&emsp;

# 构建视觉单词的离线字典

## 1 字典
使用词袋模型时，需要先训练得到一个字典。

ORB 特征描述子为一个 $256bit$ 的二进制向量，也就是说 ORB 特征在向量空间的取值有 $2^{256}$ 种可能。

训练过程：
- 选取一个庞大的数据集（里如果 10 万张图像）
- 将数据集中提取出的所有 `ORB 特征点` 放入向量空间
- 采用 `海明距离` 度量向量空间中特征点之间的距离
- 对特征点进行聚类
    - 将向量中距离相近的 k 个特征点归结为同一类
    - 并用一个平均特征来表示整体，这个平均特征就是一个单词。
    - K-Means
    - K-Means++
    - SVM 等

&emsp;
## 2 字典的树结构
假设每张图形提取 200 个特征点，整个数据集一共可提取 $M=10^5\times 200$ 个特征点，经过 k-means 聚类后，可以得到 $\frac{M}{k}$ 个不同的单词，这个单词量很庞大，如果要查 `某个特征点` 属于哪个 `单词`，搜索复杂度将非常高。

为了提高搜索效率，我们将 `单词` 再一次进行聚类，经过 d 次聚类后，就得到了一个具有 d 层的 k 叉树，树的分支数 k 和层数可以根据需要选择。
- 三角形：特征点
- 正方形：单词
- 五角形：的第二次聚类的结果
- ...

<div align="center">
    <image src="./imgs/4.3.1.png" width = 500>
    <h4>聚类</h>
</div>

&emsp;
## 3 单词的权重（IDF）
在训练该 k 叉树字典时，还要给字典中的每一个单词赋予一个权重，通常为IDF（Inverse Document Frequency，逆文本频率指数）。

例如我们语言中有大量的连接词和助词，这些词没有实质性的意义并且出现频次还很高，即一个词越常见其独特性越低，也就是说其重要性越低。

同样在视觉中，哪些在图像训练集中越常见的单词，重要性越低，单词重要性权重 IDF 公式如下：
$$IDF_i = log\frac{n}{n_i}$$



利用大量的图像训练数据，经过漫长的训练就构件好了一个视觉单词的离线字典。这个离线字典包含：
- 用于组织视觉单词（也就是叶子节点）的 k 叉树
- 每个单词所对应的重要性权重（即IDF值）