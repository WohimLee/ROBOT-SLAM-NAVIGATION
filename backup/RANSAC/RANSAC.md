&emsp;
# RANSAC 算法
- 知乎：https://zhuanlan.zhihu.com/p/62238520
## 1 RANSAC简介
`RANSAC(RAndom SAmple Consensus，随机采样一致)` 算法最早是由 Fischler 和 Bolles 在 SRI 上提出用来解决 LDP(Location Determination Proble) 问题的。

例如，我们得到了一组数据，包含了两种数据：
- 内点（inliers）：准确的数据
- 外点（outliers）：噪声（有误差的）数据


&emsp;
## 2 算法基本思想和流程
$RANSAC$ 通过反复、随机选择数据，用最小二乘法，一直迭代出比较好的模型。

>具体的实现步骤
1. 数学建模
2. 选择出可以计算出模型的最小数据子集；(对于直线拟合来说就是两个点，对于计算 Homography 矩阵就是4个点)
3. 使用这个数据子集来计算出数据模型；
4. 将所有数据带入这个模型，计算出符合条件的 `内点（inliers）`的数目，所谓的符合条件的内点是：有一个阈值，在一定误差范围内，因为不可能100%准确
5. 比较当前模型和之前推出的最好的模型的“内点“的数量，记录最大“内点”数的模型参数和“内点”数；
6. 重复1-4步，直到迭代结束或者当前模型已经足够好了(“内点数目大于一定数量”)。

&emsp;
## 3 迭代次数推导
这里有一点就是迭代的次数我们应该选择多大呢？这个值是否可以事先知道应该设为多少呢？还是只能凭经验决定呢？ 这个值其实是可以估算出来的。下面我们就来推算一下。

1. 假设 `内点` 在数据中的占比为 $t$
$$t=\frac{n_{inliers}}{n_{inliers}+n_{outliers}}$$

2. 我们每次计算模型使用 $N$ 个点，$N$ 个点都是 $inliers$ 的概率为：$t^N$
3. $P_{N个点是inlier} + P_{至少有一个点是outlier} = 1$
4. 选取的点至少有一个外点的情况就是
$$1-t^N$$

5. 迭代 $k$ 次，$(1-t^N)^k$  就是 $k$ 次迭代计算模型都至少采样到一个“外点”去计算模型的概率。那么能采样到`正确的inlier` $N$ 个点去计算的概率就是

$$P=1-(1-t^N)^k$$

通过上式，可以求得
$$k=\frac{log(1-P)}{log(1-t^N)}$$

“内点”的概率 $t$ 通常是一个先验值。然后 $P$ 是我们希望 $RANSAC$ 得到正确模型的概率。如果事先不知道 t 的值，可以使用自适应迭代次数的方法。也就是一开始设定一个无穷大的迭代次数，然后每次更新模型参数估计的时候，用当前的“内点”比值当成 t 来估算出迭代次数。